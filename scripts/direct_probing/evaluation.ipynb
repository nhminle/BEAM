{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BEAM - Direct Probing Task Evaluation\n",
    "This notebook analyzes the performance of a large language model (LLM) that has been probed to identify the **book title** and **author name** based on a passage from the book. The goal of this analysis is to determine whether the model's predictions are an **exact match** for the correct book title and author name.\n",
    "\n",
    "The dataset used in this analysis contains the following key fields:\n",
    "- **Passage**: A snippet from a book\n",
    "- **Predicted Title**: The title predicted by the LLM\n",
    "- **Predicted Author**: The author predicted by the LLM\n",
    "\n",
    "## Workflow Outline\n",
    "This notebook will perform the following steps:\n",
    "1. **Data Loading**: Import the CSV containing LLM predictions and true values.\n",
    "2. **Exact Match Checking**: Compare predicted values with true values to determine correctness.\n",
    "3. **Result Analysis**: Calculate metrics such as accuracy and error rate.\n",
    "4. **Visualization**: Create visualizations to display the results, including correct vs incorrect predictions.\n",
    "\n",
    "## Tools and Libraries\n",
    "We will be using the following libraries for this analysis:\n",
    "- **Pandas** for data manipulation\n",
    "- **Matplotlib** and **Seaborn** for visualization\n",
    "- **Numpy** for numerical operations\n",
    "\n",
    "The analysis will help us better understand the model's performance in recognizing book titles and authors based on textual passages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import unidecode\n",
    "import evaluate\n",
    "import sklearn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  en  \\\n",
      "0  Pretty soon I wanted to smoke, and asked the w...   \n",
      "1  Now she had got a start, and she went on and t...   \n",
      "2  Miss Watson she kept pecking at me, and it got...   \n",
      "3  I set down again, a-shaking all over, and got ...   \n",
      "4  We went to a clump of bushes, and Tom made eve...   \n",
      "\n",
      "                                          en_results  \\\n",
      "0  \"title\": \"The Adventures of Huckleberry Finn\",...   \n",
      "1  \"title\": \"The Adventures of Huckleberry Finn\",...   \n",
      "2  \"title\": \"The Adventures of Huckleberry Finn\",...   \n",
      "3  \"title\": \"The Adventures of Huckleberry Finn\",...   \n",
      "4  \"title\": \"The Adventures of Tom Sawyer\", \"auth...   \n",
      "\n",
      "                                                  es  \\\n",
      "0  En seguida me daban ganas de fumar y le pedía ...   \n",
      "1  Entonces ella se lanzaba a contarme todo lo de...   \n",
      "2  Un día la señorita Watson no paraba de meterse...   \n",
      "3  Volví a sentarme, todo tiritando, y saqué la p...   \n",
      "4  Fuimos a una mata de arbustos y Tom hizo que t...   \n",
      "\n",
      "                                          es_results  \\\n",
      "0  \"title\": \"Las aventuras de Huckleberry Finn\",\"...   \n",
      "1  \"title\": \"Las aventuras de Huckleberry Finn\",\"...   \n",
      "2  \"title\": \"Las aventuras de Huckleberry Finn\",\"...   \n",
      "3  \"title\": \"Las aventuras de Huckleberry Finn\",\"...   \n",
      "4  \"title\": \"Las aventuras de Huckleberry Finn\",\"...   \n",
      "\n",
      "                                                  tr  \\\n",
      "0  Bir süre sonra canım tütün çekti ve dul bayand...   \n",
      "1  Artık çenesi açılmıştı, iyi yer hakkında ne va...   \n",
      "2  Bayan Watson nasihatlerini ve azarlarını peş p...   \n",
      "3  Zangır zangır titreyerek tekrar oturdum ve içm...   \n",
      "4  Bir çalı kümesinin oraya gittik ve Tom herkese...   \n",
      "\n",
      "                                          tr_results  \\\n",
      "0  \"title\": \"İnsancıklar\",\"author\": \"Fyodor Dosto...   \n",
      "1  \"title\": \"The Adventures of Huckleberry Finn\",...   \n",
      "2  \"title\": \"The Adventures of Huckleberry Finn\",...   \n",
      "3  \"title\": \"The Adventures of Tom Sawyer\",\"autho...   \n",
      "4  \"title\": \"The Adventures of Tom Sawyer\",\"autho...   \n",
      "\n",
      "                                                  vi  \\\n",
      "0  Lát sau tôi muốn hút thuốc, tôi mới bảo bà goá...   \n",
      "1  Cô ấy bảo đi đến chỗ đó thì người ta suốt ngày...   \n",
      "2  Cô Watson cứ bắt tôi mãi như vậy, thật là khó ...   \n",
      "3  Tôi lại ngồi xuống ghế, trong người bối rối kh...   \n",
      "4  Bọn chúng tôi đi đến một bụi rậm cây cối chi c...   \n",
      "\n",
      "                                          vi_results  \n",
      "0  \"title\": \"Những cuộc phiêu lưu của Huckleberry...  \n",
      "1  \"title\": \"Adventures of Huckleberry Finn\",\"aut...  \n",
      "2  \"title\": \"The Adventures of Huckleberry Finn\",...  \n",
      "3  \"title\": \"The Adventures of Tom Sawyer\",\"autho...  \n",
      "4  \"title\": \"The Adventures of Tom Sawyer\",\"autho...  \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('/Users/alishasrivastava/BEAM/scripts/direct_probing/results/Adventures_of_Huckleberry_Finn_direct-probe_gpt4o.csv')\n",
    "df.drop(columns=['en_title', 'en_author', 'es_title', 'es_author', 'tr_title', 'tr_author', 'vi_title', 'vi_author'], inplace=True)\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating columns for predicted author and title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running extraction for en_results\n",
      "Running extraction for es_results\n",
      "Running extraction for tr_results\n",
      "Running extraction for vi_results\n",
      "                                                  en  \\\n",
      "0  Pretty soon I wanted to smoke, and asked the w...   \n",
      "1  Now she had got a start, and she went on and t...   \n",
      "2  Miss Watson she kept pecking at me, and it got...   \n",
      "3  I set down again, a-shaking all over, and got ...   \n",
      "4  We went to a clump of bushes, and Tom made eve...   \n",
      "\n",
      "                                          en_results  \\\n",
      "0  \"title\": \"The Adventures of Huckleberry Finn\",...   \n",
      "1  \"title\": \"The Adventures of Huckleberry Finn\",...   \n",
      "2  \"title\": \"The Adventures of Huckleberry Finn\",...   \n",
      "3  \"title\": \"The Adventures of Huckleberry Finn\",...   \n",
      "4  \"title\": \"The Adventures of Tom Sawyer\", \"auth...   \n",
      "\n",
      "                                                  es  \\\n",
      "0  En seguida me daban ganas de fumar y le pedía ...   \n",
      "1  Entonces ella se lanzaba a contarme todo lo de...   \n",
      "2  Un día la señorita Watson no paraba de meterse...   \n",
      "3  Volví a sentarme, todo tiritando, y saqué la p...   \n",
      "4  Fuimos a una mata de arbustos y Tom hizo que t...   \n",
      "\n",
      "                                          es_results  \\\n",
      "0  \"title\": \"Las aventuras de Huckleberry Finn\",\"...   \n",
      "1  \"title\": \"Las aventuras de Huckleberry Finn\",\"...   \n",
      "2  \"title\": \"Las aventuras de Huckleberry Finn\",\"...   \n",
      "3  \"title\": \"Las aventuras de Huckleberry Finn\",\"...   \n",
      "4  \"title\": \"Las aventuras de Huckleberry Finn\",\"...   \n",
      "\n",
      "                                                  tr  \\\n",
      "0  Bir süre sonra canım tütün çekti ve dul bayand...   \n",
      "1  Artık çenesi açılmıştı, iyi yer hakkında ne va...   \n",
      "2  Bayan Watson nasihatlerini ve azarlarını peş p...   \n",
      "3  Zangır zangır titreyerek tekrar oturdum ve içm...   \n",
      "4  Bir çalı kümesinin oraya gittik ve Tom herkese...   \n",
      "\n",
      "                                          tr_results  \\\n",
      "0  \"title\": \"İnsancıklar\",\"author\": \"Fyodor Dosto...   \n",
      "1  \"title\": \"The Adventures of Huckleberry Finn\",...   \n",
      "2  \"title\": \"The Adventures of Huckleberry Finn\",...   \n",
      "3  \"title\": \"The Adventures of Tom Sawyer\",\"autho...   \n",
      "4  \"title\": \"The Adventures of Tom Sawyer\",\"autho...   \n",
      "\n",
      "                                                  vi  \\\n",
      "0  Lát sau tôi muốn hút thuốc, tôi mới bảo bà goá...   \n",
      "1  Cô ấy bảo đi đến chỗ đó thì người ta suốt ngày...   \n",
      "2  Cô Watson cứ bắt tôi mãi như vậy, thật là khó ...   \n",
      "3  Tôi lại ngồi xuống ghế, trong người bối rối kh...   \n",
      "4  Bọn chúng tôi đi đến một bụi rậm cây cối chi c...   \n",
      "\n",
      "                                          vi_results  \\\n",
      "0  \"title\": \"Những cuộc phiêu lưu của Huckleberry...   \n",
      "1  \"title\": \"Adventures of Huckleberry Finn\",\"aut...   \n",
      "2  \"title\": \"The Adventures of Huckleberry Finn\",...   \n",
      "3  \"title\": \"The Adventures of Tom Sawyer\",\"autho...   \n",
      "4  \"title\": \"The Adventures of Tom Sawyer\",\"autho...   \n",
      "\n",
      "                   en_predicted_title en_predicted_author  \\\n",
      "0  The Adventures of Huckleberry Finn          Mark Twain   \n",
      "1  The Adventures of Huckleberry Finn          Mark Twain   \n",
      "2  The Adventures of Huckleberry Finn          Mark Twain   \n",
      "3  The Adventures of Huckleberry Finn          Mark Twain   \n",
      "4        The Adventures of Tom Sawyer          Mark Twain   \n",
      "\n",
      "                  es_predicted_title es_predicted_author  \\\n",
      "0  Las aventuras de Huckleberry Finn          Mark Twain   \n",
      "1  Las aventuras de Huckleberry Finn          Mark Twain   \n",
      "2  Las aventuras de Huckleberry Finn          Mark Twain   \n",
      "3  Las aventuras de Huckleberry Finn          Mark Twain   \n",
      "4  Las aventuras de Huckleberry Finn          Mark Twain   \n",
      "\n",
      "                   tr_predicted_title tr_predicted_author  \\\n",
      "0                         İnsancıklar  Fyodor Dostoyevski   \n",
      "1  The Adventures of Huckleberry Finn          Mark Twain   \n",
      "2  The Adventures of Huckleberry Finn          Mark Twain   \n",
      "3        The Adventures of Tom Sawyer          Mark Twain   \n",
      "4        The Adventures of Tom Sawyer          Mark Twain   \n",
      "\n",
      "                          vi_predicted_title vi_predicted_author  \n",
      "0  Những cuộc phiêu lưu của Huckleberry Finn          Mark Twain  \n",
      "1             Adventures of Huckleberry Finn          Mark Twain  \n",
      "2         The Adventures of Huckleberry Finn          Mark Twain  \n",
      "3               The Adventures of Tom Sawyer          Mark Twain  \n",
      "4               The Adventures of Tom Sawyer          Mark Twain  \n"
     ]
    }
   ],
   "source": [
    "def extract_title_author(results_column):\n",
    "    results_column = results_column.fillna('').astype(str).str.strip()\n",
    "    return results_column.str.extract(r'\"title\":\\s*\"(.*?)\",\\s*\"author\":\\s*\"(.*?)\"')\n",
    "\n",
    "for language in df.columns:\n",
    "    if '_results' in language:\n",
    "        print(f'Running extraction for {language}')\n",
    "        \n",
    "        extracted_titles_authors = extract_title_author(df[language])\n",
    "        language_suffix = language.replace('_results', '')\n",
    "        \n",
    "        df[f'{language_suffix}_predicted_title'] = extracted_titles_authors[0]\n",
    "        df[f'{language_suffix}_predicted_author'] = extracted_titles_authors[1]\n",
    "\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Checking integrity of data - no NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Checking integrity for language: en\n",
      "No NaN in en_predicted_title\n",
      "No NaN values in en_predicted_author\n",
      "No unexpected empty values in en_predicted_title\n",
      "No unexpected empty values in en_predicted_author\n",
      "\n",
      "Checking integrity for language: es\n",
      "No NaN in es_predicted_title\n",
      "No NaN values in es_predicted_author\n",
      "No unexpected empty values in es_predicted_title\n",
      "No unexpected empty values in es_predicted_author\n",
      "\n",
      "Checking integrity for language: tr\n",
      "No NaN in tr_predicted_title\n",
      "No NaN values in tr_predicted_author\n",
      "No unexpected empty values in tr_predicted_title\n",
      "No unexpected empty values in tr_predicted_author\n",
      "\n",
      "Checking integrity for language: vi\n",
      "No NaN in vi_predicted_title\n",
      "No NaN values in vi_predicted_author\n",
      "No unexpected empty values in vi_predicted_title\n",
      "No unexpected empty values in vi_predicted_author\n"
     ]
    }
   ],
   "source": [
    "def check_data_integrity(language):\n",
    "    print(f\"\\nChecking integrity for language: {language}\")\n",
    "    predicted_titles = df[f'{language}_predicted_title']\n",
    "    predicted_authors = df[f'{language}_predicted_author']\n",
    "    \n",
    "    if predicted_titles.isnull().any():\n",
    "        print(f\"NaN values found in {language}_predicted_title:\")\n",
    "        print(predicted_titles[predicted_titles.isnull()])\n",
    "    else:\n",
    "        print(f\"No NaN in {language}_predicted_title\")\n",
    "\n",
    "    if predicted_authors.isnull().any():\n",
    "        print(f\"NaN values found in {language}_predicted_author:\")\n",
    "        print(predicted_authors[predicted_authors.isnull()])\n",
    "    else:\n",
    "        print(f\"No NaN values in {language}_predicted_author\")\n",
    "\n",
    "    unexpected_titles = predicted_titles[predicted_titles.str.strip() == '']\n",
    "    if not unexpected_titles.empty:\n",
    "        print(f\"Unexpected empty values in {language}_predicted_title:\")\n",
    "        print(unexpected_titles)\n",
    "    else:\n",
    "        print(f\"No unexpected empty values in {language}_predicted_title\")\n",
    "\n",
    "    unexpected_authors = predicted_authors[predicted_authors.str.strip() == '']\n",
    "    if not unexpected_authors.empty:\n",
    "        print(f\"Unexpected empty values in {language}_predicted_author:\")\n",
    "        print(unexpected_authors)\n",
    "    else:\n",
    "        print(f\"No unexpected empty values in {language}_predicted_author\")\n",
    "\n",
    "for language in ['en', 'es', 'tr', 'vi']: \n",
    "    check_data_integrity(language)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating F1 Exact Match\n",
    "- **Using Unidecode for normalization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Title: The Adventures of Huckleberry Finn, Actual Title: The Adventures of Huckleberry Finn\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: 'The Adventures of Huckleberry Finn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[56], line 22\u001b[0m\n\u001b[1;32m     19\u001b[0m actual_authors \u001b[38;5;241m=\u001b[39m book_authors[language]\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Exact match F1 scores for titles\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m df[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlanguage\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_exact_match_title\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mlanguage\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_predicted_title\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPredicted Title: \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mx\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m, Actual Title: \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mactual_titles\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Debugging print\u001b[39;49;00m\n\u001b[1;32m     25\u001b[0m \u001b[43m        \u001b[49m\u001b[43mf1_metric\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredictions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43munidecode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munidecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreferences\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43munidecode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munidecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mactual_titles\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mf1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\n\u001b[1;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnotna\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Handle NaN case\u001b[39;49;00m\n\u001b[1;32m     27\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# Exact match F1 scores for authors\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m#df[f'{language}_exact_match_author'] = df[f'{language}_predicted_author'].apply(\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m#    lambda x: (\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m#    )[1]  # Return the F1 score\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m#)\u001b[39;00m\n",
      "File \u001b[0;32m~/BEAM/.venv/lib/python3.9/site-packages/pandas/core/series.py:4917\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[1;32m   4789\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[1;32m   4790\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4791\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4796\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   4797\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m   4798\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4799\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4800\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4915\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4916\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4917\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4918\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4920\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4922\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4923\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4924\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/BEAM/.venv/lib/python3.9/site-packages/pandas/core/apply.py:1427\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[1;32m   1426\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[0;32m-> 1427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/BEAM/.venv/lib/python3.9/site-packages/pandas/core/apply.py:1507\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1501\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[1;32m   1504\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[1;32m   1505\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[1;32m   1506\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1507\u001b[0m mapped \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1508\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[1;32m   1509\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1512\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1513\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[0;32m~/BEAM/.venv/lib/python3.9/site-packages/pandas/core/base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[0;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[1;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[0;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/BEAM/.venv/lib/python3.9/site-packages/pandas/core/algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[0;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[1;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[1;32m   1747\u001b[0m     )\n",
      "File \u001b[0;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "Cell \u001b[0;32mIn[56], line 25\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     19\u001b[0m actual_authors \u001b[38;5;241m=\u001b[39m book_authors[language]\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Exact match F1 scores for titles\u001b[39;00m\n\u001b[1;32m     22\u001b[0m df[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlanguage\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_exact_match_title\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlanguage\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_predicted_title\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m x: (\n\u001b[1;32m     24\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPredicted Title: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Actual Title: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mactual_titles[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m),  \u001b[38;5;66;03m# Debugging print\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m         \u001b[43mf1_metric\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredictions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43munidecode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munidecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreferences\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43munidecode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munidecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mactual_titles\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf1\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     26\u001b[0m     )[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mnotna(x) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m  \u001b[38;5;66;03m# Handle NaN case\u001b[39;00m\n\u001b[1;32m     27\u001b[0m )\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# Exact match F1 scores for authors\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m#df[f'{language}_exact_match_author'] = df[f'{language}_predicted_author'].apply(\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m#    lambda x: (\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m#    )[1]  # Return the F1 score\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m#)\u001b[39;00m\n",
      "File \u001b[0;32m~/BEAM/.venv/lib/python3.9/site-packages/evaluate/module.py:455\u001b[0m, in \u001b[0;36mEvaluationModule.compute\u001b[0;34m(self, predictions, references, **kwargs)\u001b[0m\n\u001b[1;32m    452\u001b[0m compute_kwargs \u001b[38;5;241m=\u001b[39m {k: kwargs[k] \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m kwargs \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_feature_names()}\n\u001b[1;32m    454\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(v \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m inputs\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[0;32m--> 455\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    456\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_finalize()\n\u001b[1;32m    458\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache_file_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/BEAM/.venv/lib/python3.9/site-packages/evaluate/module.py:520\u001b[0m, in \u001b[0;36mEvaluationModule.add_batch\u001b[0;34m(self, predictions, references, **kwargs)\u001b[0m\n\u001b[1;32m    518\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(column) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    519\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enforce_nested_string_type(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mselected_feature_format[key], column[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m--> 520\u001b[0m     batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselected_feature_format\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    521\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter\u001b[38;5;241m.\u001b[39mwrite_batch(batch)\n\u001b[1;32m    522\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (pa\u001b[38;5;241m.\u001b[39mArrowInvalid, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n",
      "File \u001b[0;32m~/BEAM/.venv/lib/python3.9/site-packages/datasets/features/features.py:2024\u001b[0m, in \u001b[0;36mFeatures.encode_batch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m   2022\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, column \u001b[38;5;129;01min\u001b[39;00m batch\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m   2023\u001b[0m     column \u001b[38;5;241m=\u001b[39m cast_to_python_objects(column)\n\u001b[0;32m-> 2024\u001b[0m     encoded_batch[key] \u001b[38;5;241m=\u001b[39m [encode_nested_example(\u001b[38;5;28mself\u001b[39m[key], obj, level\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m column]\n\u001b[1;32m   2025\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m encoded_batch\n",
      "File \u001b[0;32m~/BEAM/.venv/lib/python3.9/site-packages/datasets/features/features.py:2024\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   2022\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, column \u001b[38;5;129;01min\u001b[39;00m batch\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m   2023\u001b[0m     column \u001b[38;5;241m=\u001b[39m cast_to_python_objects(column)\n\u001b[0;32m-> 2024\u001b[0m     encoded_batch[key] \u001b[38;5;241m=\u001b[39m [\u001b[43mencode_nested_example\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m column]\n\u001b[1;32m   2025\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m encoded_batch\n",
      "File \u001b[0;32m~/BEAM/.venv/lib/python3.9/site-packages/datasets/features/features.py:1350\u001b[0m, in \u001b[0;36mencode_nested_example\u001b[0;34m(schema, obj, level)\u001b[0m\n\u001b[1;32m   1347\u001b[0m \u001b[38;5;66;03m# Object with special encoding:\u001b[39;00m\n\u001b[1;32m   1348\u001b[0m \u001b[38;5;66;03m# ClassLabel will convert from string to int, TranslationVariableLanguages does some checks\u001b[39;00m\n\u001b[1;32m   1349\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(schema, (Audio, Image, ClassLabel, TranslationVariableLanguages, Value, _ArrayXD)):\n\u001b[0;32m-> 1350\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mschema\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode_example\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1351\u001b[0m \u001b[38;5;66;03m# Other object should be directly convertible to a native Arrow type (like Translation and Translation)\u001b[39;00m\n\u001b[1;32m   1352\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj\n",
      "File \u001b[0;32m~/BEAM/.venv/lib/python3.9/site-packages/datasets/features/features.py:527\u001b[0m, in \u001b[0;36mValue.encode_example\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    525\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(value)\n\u001b[1;32m    526\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m pa\u001b[38;5;241m.\u001b[39mtypes\u001b[38;5;241m.\u001b[39mis_integer(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpa_type):\n\u001b[0;32m--> 527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    528\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m pa\u001b[38;5;241m.\u001b[39mtypes\u001b[38;5;241m.\u001b[39mis_floating(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpa_type):\n\u001b[1;32m    529\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mfloat\u001b[39m(value)\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: 'The Adventures of Huckleberry Finn'"
     ]
    }
   ],
   "source": [
    "book_data = {\n",
    "    'en': [\"The Adventures of Huckleberry Finn\"],\n",
    "    'es': [\"Las aventuras de Huckleberry Finn\", \"The Adventures of Huckleberry Finn\"],\n",
    "    'tr': [\"The Adventures of Huckleberry Finn\"],\n",
    "    'vi': [\"The Adventures of Huckleberry Finn\"]\n",
    "}\n",
    "book_authors = {\n",
    "    'en': [\"Mark Twain\"],\n",
    "    'es': [\"Mark Twain\"],\n",
    "    'tr': [\"Mark Twain\"],\n",
    "    'vi': [\"Mark Twain\"]\n",
    "}\n",
    "\n",
    "f1_metric = evaluate.load(\"f1\")\n",
    "\n",
    "# Adding exact match columns for each language\n",
    "for language in ['en', 'es', 'tr', 'vi']:\n",
    "    actual_titles = book_data[language]\n",
    "    actual_authors = book_authors[language]\n",
    "    \n",
    "    # Exact match F1 scores for titles\n",
    "    df[f'{language}_exact_match_title'] = df[f'{language}_predicted_title'].apply(\n",
    "        lambda x: (\n",
    "            print(f\"Predicted Title: {x}, Actual Title: {actual_titles[0]}\"),  # Debugging print\n",
    "            f1_metric.compute(predictions=[unidecode.unidecode(str(x))], references=[unidecode.unidecode(actual_titles[0])])['f1'] if isinstance(x, str) else 0\n",
    "        )[1] if pd.notna(x) else 0  # Handle NaN case\n",
    "    )\n",
    "    \n",
    "    # Exact match F1 scores for authors\n",
    "    #df[f'{language}_exact_match_author'] = df[f'{language}_predicted_author'].apply(\n",
    "    #    lambda x: (\n",
    "    #        print(f\"Predicted Author: {x}, Actual Author: {actual_authors[0]}\"),  # Debugging print\n",
    "    #        f1_metric.compute(predictions=[unidecode.unidecode(x)], references=[unidecode.unidecode(actual_authors[0])])['f1']\n",
    "    #    )[1]  # Return the F1 score\n",
    "    #)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
